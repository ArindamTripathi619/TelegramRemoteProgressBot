# Bot Monitor Configuration

telegram:
  # Get bot token from @BotFather on Telegram
  bot_token: "${TELEGRAM_BOT_TOKEN}"
  # Your Telegram chat ID (use bot-monitor setup to find it)
  chat_id: "${TELEGRAM_CHAT_ID}"

llm:
  # Provider: openai, anthropic, groq, ollama
  provider: "openai"
  api_key: "${LLM_API_KEY}"
  model: "gpt-4o-mini"
  # Optional: for Ollama or custom endpoints
  base_url: null
  
  # Token usage optimization (reduce costs/rate limits)
  optimization:
    enable_cache: true  # Cache repeated error analysis
    cache_max_entries: 100  # Max cached analyses
    cache_ttl_seconds: 3600  # Cache lifetime (1 hour)
    max_context_lines: 15  # Trim context to N lines
    include_timestamps: false  # Remove timestamps to save tokens
    use_local_patterns: true  # Match known patterns locally
    skip_llm_for_info: true  # Don't use LLM for INFO events

notification:
  # Debounce period in seconds (group similar events)
  debounce_seconds: 300
  # Maximum notifications per hour
  rate_limit_per_hour: 10
  # Which severity levels to send
  severity_levels: [critical, warning, info]

# Process information for progress tracking
process:
  name: "My Process"
  description: "Training ML model on large dataset"
  keywords:
    - "progress"
    - "processed"
    - "epoch"
    - "batch"
    - "complete"
  expected_duration_minutes: 60  # Optional: helps with time-based estimation
  completion_indicators:  # Optional: regex patterns for parsing progress
    - pattern: "Processed (\\d+)/(\\d+)"
      type: "fraction"
    - pattern: "Progress: (\\d+)%"
      type: "percentage"

# Progress tracking settings
progress_tracking:
  enabled: true
  update_interval_percent: 10  # Send updates every 10%
  min_update_interval_seconds: 300  # Min 5 min between updates
  stall_threshold_minutes: 30  # Alert if no progress for 30 min
  estimation_mode: "auto"  # auto, log-based, time-based, llm-assisted

# Interactive features (two-way communication)
interactive:
  listen_for_messages: true  # Poll for user messages
  status_on_any_message: true  # Any message triggers status report

# Severity pattern library (local detection, saves LLM calls)
severity_patterns:
  critical:
    - "segmentation fault|segfault"
    - "out of memory|oom|memory exhausted"
    - "panic|kernel panic"
    - "fatal\\s+error"
    - "database\\s+(connection\\s+)?failed"
    - "core dumped"
  warning:
    - "deprecated"
    - "retry|retrying"
    - "timeout|timed\\s+out"
    - "connection\\s+(lost|dropped)"
    - "warn(ing)?:"
  info:
    - "start(ed|ing)"
    - "complet(ed|ion)"
    - "initializ(ed|ing)"
    - "success(ful|fully)?"

monitors:
  # Monitor a log file
  - type: file
    name: "Application Logs"
    path: "/var/log/myapp.log"
    keywords: ["ERROR", "FATAL", "Exception", "Traceback"]
  
  # Monitor a process by PID
  - type: pid
    name: "Training Process"
    pid: 12345
    check_interval: 30
  
  # Monitor systemd journal
  - type: journal
    name: "Web Service"
    unit: "nginx.service"
    since: "5 minutes ago"
