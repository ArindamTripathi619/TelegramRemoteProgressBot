# Bot Monitor Configuration

telegram:
  # Get bot token from @BotFather on Telegram
  bot_token: "${TELEGRAM_BOT_TOKEN}"
  # Your Telegram chat ID (use bot-monitor setup to find it)
  chat_id: "${TELEGRAM_CHAT_ID}"

llm:
  # Provider: openai, anthropic, groq, ollama
  provider: "openai"
  api_key: "${LLM_API_KEY}"
  model: "gpt-4o-mini"
  # Optional: for Ollama or custom endpoints
  base_url: null

notification:
  # Debounce period in seconds (group similar events)
  debounce_seconds: 300
  # Maximum notifications per hour
  rate_limit_per_hour: 10
  # Which severity levels to send
  severity_levels: [critical, warning, info]

# Process information for progress tracking
process:
  name: "My Process"
  description: "Training ML model on large dataset"
  keywords:
    - "progress"
    - "processed"
    - "epoch"
    - "batch"
    - "complete"
  expected_duration_minutes: 60  # Optional: helps with time-based estimation
  completion_indicators:  # Optional: regex patterns for parsing progress
    - pattern: "Processed (\\d+)/(\\d+)"
      type: "fraction"
    - pattern: "Progress: (\\d+)%"
      type: "percentage"

# Progress tracking settings
progress_tracking:
  enabled: true
  update_interval_percent: 10  # Send updates every 10%
  min_update_interval_seconds: 300  # Min 5 min between updates
  stall_threshold_minutes: 30  # Alert if no progress for 30 min
  estimation_mode: "auto"  # auto, log-based, time-based, llm-assisted

# Interactive features (two-way communication)
interactive:
  listen_for_messages: true  # Poll for user messages
  status_on_any_message: true  # Any message triggers status report

monitors:
  # Monitor a log file
  - type: file
    name: "Application Logs"
    path: "/var/log/myapp.log"
    keywords: ["ERROR", "FATAL", "Exception", "Traceback"]
  
  # Monitor a process by PID
  - type: pid
    name: "Training Process"
    pid: 12345
    check_interval: 30
  
  # Monitor systemd journal
  - type: journal
    name: "Web Service"
    unit: "nginx.service"
    since: "5 minutes ago"
